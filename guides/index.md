---
layout: default
title: Home
---

# All Technical Notes I Could think of

<h3> Head over to </h3>
- [Written by me](#bySelf)
- [Others](#byOthers)
- [Academics at IIIT Jabalpur](#acadTalk)

<div id="bySelf"></div>
<hr style="border:1px solid gray">
Ƹ̵̡Ӝ̵̨̄Ʒ Ƹ̵̡Ӝ̵̨̄Ʒ Ƹ̵̡Ӝ̵̨̄Ʒ <br>
butterfly as a line break

<h2>
Written by me
</h2>

1. [Getting Started With ML](/guides/startml.md)

2. [What even are RAGs](https://docs.google.com/document/d/1GzmrIF3Z7mEk_lhTqhF4HicyINtNCHv21O3a2Guu7q4/edit?usp=sharing)
Saw Sony Research asking for RAGs for undergrad research positions, hence this.

3. [Positional Encoding in Transformers](https://medium.com/@aryan1113/positional-encoding-in-transformers-a1f24a7aa382)

4. [IDL by Alexander Amini Notes](https://hackmd.io/@aryan1113/H1RmTzNxh)

5. [Initializations in Deep Learning](https://hackmd.io/@aryan1113/r1xZwK-Z2)

6. [Summary of some Netflix Tech Blogs](https://hackmd.io/@aryan1113/SyTLg6VN2)

7. [Exploring Recurrent Neural Networks, will be shifted to the repo soon](https://docs.google.com/document/d/10P_5bxETnO1mgMMKNV7HryTrPkGZV7fYp4WWnTUHFmY/edit?usp=sharing)

8. [BSoC Summary Sheet, whish was a fun toned down ML Primer for sophomores](https://docs.google.com/document/d/1Wbuv9AETVUAQhO80Jhu5PAr0CVUAqZ0JPP4D1rEntT0/edit?usp=sharing)

9. [Linear Least Squares Method](https://aryan1113.substack.com/p/least-squares-method-for-linear-regression)

10. [Stock Price Regressor at IITK](https://hackmd.io/@aryan1113/B1ekeZlqW3)

<div id="byOthers"></div>
<hr style="border:1px solid gray">
龴ↀ◡ↀ龴 <br>
cat as a line break

<h2>
Others that I really liked
</h2>

Most of these have been put up on the [college discord server](https://discord.gg/b4szAeN3gq) under the channel "#data-n-stuff"
<br>

1. [Overfitting explained simply](https://www.ibm.com/cloud/learn/overfitting)

2. [Leetcode for Data Science](https://www.stratascratch.com/)

3. [Fundamentals of ML, IITD](https://www.cse.iitd.ac.in/~parags/teaching/2013/au13/csl341/)

4. [Why read, a blog by an alum of 2013-17 batch](https://indiaai.gov.in/article/read-and-watch-lectures-to-build-a-foundation)

5. [ML Primer, using xkcd templates](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)

6. [DL Playlist by Prof Bryce, must watch alongside IDL by Goodfellow](https://www.youtube.com/playlist?list=PLgPbN3w-ia_PeT1_c5jiLW3RJdR7853b9)

7. [Ensemble Learning](https://fritz.ai/ensemble-learning/)

8. [Revise ML through Stanford cheatsheets](https://stanford.edu/~shervine/teaching/cs-229/)

9. Activation Functions
- [Comparing activations, link broken perhaps](https://wandb.ai/shweta/Activation%20Functions/reports/Activation-Functions-Compared-With-Experiments--VmlldzoxMDQwOTQ)
- [Short discussion on ReLU and Sigmoid](https://wandb.ai/ayush-thakur/dl-question-bank/reports/ReLU-vs-Sigmoid-Function-in-Deep-Neural-Networks--VmlldzoyMDk0MzI)

10. [Batch Norm explained](https://e2eml.school/batch_normalization.html)

11. AutoEncoders and Variational Auto Encoders
- [Watch vids 44 - 50](https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH)
- [Variational AutoEncoders](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)
- [Paper, Tutorial on VAE](https://arxiv.org/pdf/1606.05908.pdf)

12. Do we Use Dropouts with CNN's ?
- [Experimenting with networks](https://nchlis.github.io/2017_08_10/page.html)
- [KdNuggets Blog](https://www.kdnuggets.com/2018/09/dropout-convolutional-networks.html)

12. [Deep Dream](https://www.americanscientist.org/sites/americanscientist.org/files/20151081452611494-2015-11Hayes.pdf). Firing select neurons in the network and propogate changes to the input image, gives weird but interesting patterns.

13. [Exhaustive Blog on LSTMs](https://towardsdatascience.com/tutorial-on-lstm-a-computational-perspective-f3417442c2cd)

14. [Enforcing Constraints at Amazon](https://www.amazon.science/blog/how-to-compute-the-optimal-way-to-package-amazon-products). Really cheeky way to enforce constraints.

- If a package size had no reported damage for the product, dummy datapoints were added to the DB such that even for bigger package sizes no damage was reported. 
- Similarly to enforce the negative constraint, if damage was reported for a particular size, all sizes below it were added in the DB with damage = True

<div id="acadTalk"></div>
<hr style="border:1px solid gray">
(╯°□°）╯ ︵ ┻━┻ <br>
tableflip as a line break


<h2>
Troubled by Academics ?
</h2>
Check out past year papers, [compiled and maintained by BitByte (hopefully)](https://drive.google.com/drive/folders/1v4t1wpWpf_ydZ0o_llEwDZ-wHEsyLsIL)

[Academic Info Page](http://172.27.16.19/academic%20info/)
[Academic Question Bank, is not revised periodically](http://172.27.16.19/academic%20info/Examination%20Question%20Bank/)

1. SEM-1
<br>
[Acad Talk](https://docs.google.com/document/d/1CW2ranNFVfeqiD4NWqRNo9-IUBE11BhI4jGfQ7Bds7g/edit?usp=sharing)

2. SEM-2
<br>
[Acad Talk](https://docs.google.com/document/d/1YvHvrHV_Zkx6_Non5KyDCCaKtMnjqLQnewdgBuSnGtg/edit?usp=sharing)

3. SEM-3
<br>
[Acad Talk](https://docs.google.com/document/d/1_0a6lL4QqTD4sEsYViwu_vg7O9wwKan3XtKipZUu_7A/edit?usp=sharing)

4. SEM-4
<br>
[Acad Talk](https://docs.google.com/document/d/1BVxx9VzPHTQHVTZgEPf-n52Eficdb1-s_RiVDWFm4y4/edit?usp=sharing)
- [Introduction to Deep Learning by AV](https://hackmd.io/@aryan1113/HkNdNqBF6)
- [CST Lab Guide](https://hackmd.io/@aryan1113/By7TiV53j)

5. SEM-5
<br>
[Acad Talk](https://docs.google.com/document/d/1pIOrOy3FqmhPHAM2wfNc7i0ijShKvQp_k_X7E_je60U/edit?usp=sharing)
- [Verilog Lab Guide](https://hackmd.io/@aryan1113/ryfNw0xRh)

6. SEM-6
<br>
[Acad Talk](https://docs.google.com/document/d/1RfSvKxaSqWp1kMpCf5v8mYzAdjRkzNzUMtan9ffGcKk/edit?usp=sharing)
- [LTSpice Lab Guide](https://hackmd.io/@aryan1113/BJhIrZ5cT)

7. SEM-7
<br>
[Acad Talk](https://docs.google.com/document/d/1vTvo8ANukV57xihpKCUbC041aXND0ZSpNUjJgGvs6sI/edit?usp=sharing)

8. SEM-8
<br>
[Acad Talk](https://docs.google.com/document/d/1sF3ipf2euf6_oQqCbjh4cWWvTQ98Lq7JqRhwfd1Zqms/edit?usp=sharing)